{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"RoboReplay","text":"<p>The DVR for robot behavior \u2014 record, replay, diagnose, and share robot execution data.</p> <p>RoboReplay is a lightweight, framework-agnostic Python library that works with MuJoCo, Isaac Sim, ROS2, Gymnasium, real hardware \u2014 anything with a Python API.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Record \u2014 Stream robot data to compressed <code>.rrp</code> files with automatic schema inference</li> <li>Replay \u2014 Random-access indexing, slicing, and channel queries</li> <li>Diagnose \u2014 Statistical anomaly detection (drops, spikes, flatlines) + optional LLM-powered analysis via Claude</li> <li>Compare \u2014 Side-by-side recording diff with divergence detection</li> <li>Export \u2014 CSV files and self-contained interactive HTML viewer with Chart.js</li> <li>Gymnasium Wrapper \u2014 <code>roboreplay.wrap(env)</code> for automatic recording of observations, actions, and rewards</li> <li>Rich CLI \u2014 <code>info</code>, <code>diagnose</code>, <code>compare</code>, <code>export</code>, <code>plot</code> commands with beautiful terminal output</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from roboreplay import Recorder, Replay\n\n# Record\nwith Recorder(\"my_experiment\", metadata={\"robot\": \"panda\"}) as rec:\n    for step in range(100):\n        rec.step(state=get_state(), action=get_action(), reward=get_reward())\n\n# Replay\nr = Replay(\"my_experiment.rrp\")\nprint(r)            # Summary\nprint(r[50])        # Data at step 50\nprint(r.channels)   # Channel names\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install roboreplay                  # Core\npip install roboreplay[viz]             # + matplotlib plotting\npip install roboreplay[gym]             # + Gymnasium wrapper\npip install roboreplay[diagnose]        # + LLM diagnosis (Claude API)\npip install roboreplay[all]             # Everything\n</code></pre> <p>See the Installation guide for full details.</p>"},{"location":"#why-roboreplay","title":"Why RoboReplay?","text":"<ul> <li>Minimal dependencies \u2014 Core: numpy, h5py, click, rich, pydantic</li> <li>Framework-agnostic \u2014 Pass numpy arrays, we store them</li> <li>Streaming writes \u2014 Never accumulates full episodes in RAM</li> <li>Offline-first \u2014 Everything works without internet</li> <li>64 tests passing \u2014 Comprehensive test coverage across all features</li> </ul>"},{"location":"#examples","title":"Examples","text":"<pre><code>python examples/simulated_pick_place.py   # 7-DOF pick-and-place with grasp slip failure\npython examples/custom_robot.py           # 6-DOF arm, success vs failure comparison\npython examples/batch_analysis.py         # 5 recordings, batch diagnosis, CSV export\npython examples/gymnasium_cartpole.py     # CartPole with automatic recording (needs roboreplay[gym])\n</code></pre>"},{"location":"cli/","title":"CLI Reference","text":"<p>RoboReplay provides a command-line interface for quick analysis.</p>"},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#roboreplay-info","title":"<code>roboreplay info</code>","text":"<p>Show recording summary.</p> <pre><code>roboreplay info recording.rrp\n</code></pre> <p>Displays: name, robot, task, steps, channels, statistics, and events.</p>"},{"location":"cli/#roboreplay-diagnose","title":"<code>roboreplay diagnose</code>","text":"<p>Run anomaly detection on a recording.</p> <pre><code>roboreplay diagnose recording.rrp\nroboreplay diagnose recording.rrp --llm\nroboreplay diagnose recording.rrp --llm --api-key sk-ant-...\n</code></pre> <p>Options:</p> Option Default Description <code>--drop-threshold</code> 0.5 Sensitivity for drop detection (0-1) <code>--spike-threshold</code> 3.0 Standard deviations for spike detection <code>--flatline-duration</code> 20 Minimum steps for flatline detection <code>--llm</code> false Use LLM for enhanced diagnosis <code>--api-key</code> env var Anthropic API key"},{"location":"cli/#roboreplay-compare","title":"<code>roboreplay compare</code>","text":"<p>Compare two recordings side-by-side.</p> <pre><code>roboreplay compare run_a.rrp run_b.rrp\n</code></pre>"},{"location":"cli/#roboreplay-export","title":"<code>roboreplay export</code>","text":"<p>Export recording to CSV or HTML.</p> <pre><code>roboreplay export recording.rrp --format csv\nroboreplay export recording.rrp --format html\nroboreplay export recording.rrp --format csv -o exports/\nroboreplay export recording.rrp --format html -o report.html\n</code></pre> <p>Options:</p> Option Default Description <code>--format, -f</code> csv Export format: <code>csv</code> or <code>html</code> <code>--output, -o</code> auto Output directory (csv) or file (html) <code>--channel, -c</code> all Channels to export (repeatable)"},{"location":"cli/#roboreplay-plot","title":"<code>roboreplay plot</code>","text":"<p>Plot channels from a recording.</p> <pre><code>roboreplay plot recording.rrp\nroboreplay plot recording.rrp -c force -c position\nroboreplay plot recording.rrp -o plots.png\n</code></pre>"},{"location":"cli/#roboreplay-version","title":"<code>roboreplay --version</code>","text":"<pre><code>roboreplay --version\n</code></pre>"},{"location":"use-cases/","title":"Use Cases","text":""},{"location":"use-cases/#why-roboreplay","title":"Why RoboReplay?","text":"What exists What's wrong with it rosbag ROS-only. Huge files. No analysis. No querying. Weights &amp; Biases For ML training metrics, not physical robot behavior. Video recording Loses all the data. You see what happened but not why. Manual logging Everyone builds their own. Everyone hates it. <p>RoboReplay is the first framework-agnostic, pip-installable tool for recording, analyzing, and sharing robot execution data with built-in anomaly detection.</p>"},{"location":"use-cases/#works-with-any-robotics-stack","title":"Works With Any Robotics Stack","text":"Platform What you record MuJoCo <code>data.qpos</code>, <code>data.qvel</code>, <code>data.ctrl</code>, <code>data.sensordata</code> Isaac Sim Joint states, rigid body poses, sensor readings PyBullet <code>getJointStates()</code>, <code>getContactPoints()</code>, <code>getBasePositionAndOrientation()</code> ROS2 Any topic data converted to numpy in a subscriber callback Gymnasium One-line: <code>roboreplay.wrap(env)</code> \u2014 automatic obs/action/reward Real hardware Serial data, force/torque sensors, encoders, cameras \u2014 anything as numpy Custom simulation Any loop that produces numpy arrays"},{"location":"use-cases/#who-its-for","title":"Who It's For","text":"<p>RL researchers \u2014 Record every training episode. Debug why episode 4,847 failed. Compare policy v2 against v3. Wrap Gymnasium envs in one line.</p> <p>Manipulation researchers \u2014 Capture joint states, end-effector poses, gripper forces, contact forces. Diagnose grasp failures automatically. Compare successful vs failed grasps to find the exact divergence step.</p> <p>Real robot operators \u2014 Black-box recorder for teleoperation, autonomous runs, and calibration. Crash-safe streaming writes mean you never lose overnight data. Post-run anomaly detection catches hardware issues.</p> <p>Robotics teams \u2014 Batch diagnosis across fleet runs. Export HTML reports for non-technical stakeholders. CSV export for downstream analysis in pandas, MATLAB, R, or Excel.</p> <p>Students and educators \u2014 Students submit <code>.rrp</code> files as deliverables. Instructors replay, diagnose, and batch-compare submissions. HTML export for presentations without Python.</p>"},{"location":"use-cases/#concrete-workflows","title":"Concrete Workflows","text":""},{"location":"use-cases/#debugging-a-failure","title":"Debugging a failure","text":"<pre><code>r = Replay(\"failed_run.rrp\")\nr[200]                         # All sensors at the failure step\nr.events.where(\"failure\")     # What events were marked?\nresult = diagnose(\"failed_run.rrp\", use_llm=True)\nprint(result.llm_result.explanation)  # \"The robot dropped the object because...\"\n</code></pre>"},{"location":"use-cases/#ab-testing-policy-versions","title":"A/B testing policy versions","text":"<pre><code>diff = compare(\"policy_v2.rrp\", \"policy_v3.rrp\")\nprint(f\"Divergence at step {diff.divergence_step}\")\nprint(f\"Reward change: {diff.channel_diffs['reward'].mean_change_pct:+.1f}%\")\n</code></pre>"},{"location":"use-cases/#batch-fleet-analysis","title":"Batch fleet analysis","text":"<pre><code>from pathlib import Path\nfor rrp in Path(\"fleet_data/\").glob(\"*.rrp\"):\n    result = diagnose(rrp)\n    if result.has_failures:\n        export_html(rrp, output=f\"reports/{rrp.stem}.html\")\n</code></pre>"},{"location":"use-cases/#overnight-experiment-safety-net","title":"Overnight experiment safety net","text":"<pre><code>with Recorder(\"overnight_run\", path=\"/data/experiments/\") as rec:\n    for step in range(1_000_000):\n        rec.step(state=state, action=action)\n        # Crash at step 500,000? You still have 499,900+ steps safely on disk.\n</code></pre>"},{"location":"use-cases/#sim-to-real-gap-analysis","title":"Sim-to-real gap analysis","text":"<pre><code>diff = compare(\"sim_run.rrp\", \"real_run.rrp\")\n# See exactly which channels diverge and by how much between sim and real\n</code></pre>"},{"location":"use-cases/#imitation-learning-dataset","title":"Imitation learning dataset","text":"<pre><code>for demo_id in range(100):\n    with Recorder(f\"demo_{demo_id:03d}\", path=\"dataset/\") as rec:\n        while demonstrating:\n            rec.step(observation=obs, action=human_action)\n# Then: export_csv for PyTorch dataloaders\n</code></pre>"},{"location":"use-cases/#ci-regression-testing","title":"CI regression testing","text":"<pre><code>def test_grasp_succeeds():\n    with Recorder(\"test_grasp\", path=tmp / \"test.rrp\") as rec:\n        run_grasp_policy(rec)\n    result = diagnose(tmp / \"test.rrp\")\n    assert not result.has_failures\n</code></pre>"},{"location":"api/compare/","title":"Compare API","text":""},{"location":"api/compare/#roboreplay.compare.compare","title":"<code>roboreplay.compare.compare(path_a, path_b)</code>","text":"<p>Compare two recordings side-by-side.</p> <p>Analyzes per-channel statistics and finds the divergence point where the two runs start behaving differently.</p> <p>Parameters:</p> Name Type Description Default <code>path_a</code> <code>str | Path</code> <p>Path to first recording.</p> required <code>path_b</code> <code>str | Path</code> <p>Path to second recording.</p> required <p>Returns:</p> Type Description <code>CompareResult</code> <p>CompareResult with detailed comparison.</p> Source code in <code>roboreplay/compare.py</code> <pre><code>def compare(\n    path_a: str | Path,\n    path_b: str | Path,\n) -&gt; CompareResult:\n    \"\"\"Compare two recordings side-by-side.\n\n    Analyzes per-channel statistics and finds the divergence point\n    where the two runs start behaving differently.\n\n    Args:\n        path_a: Path to first recording.\n        path_b: Path to second recording.\n\n    Returns:\n        CompareResult with detailed comparison.\n    \"\"\"\n    replay_a = Replay(path_a)\n    replay_b = Replay(path_b)\n\n    shared = sorted(set(replay_a.channels) &amp; set(replay_b.channels))\n\n    channel_diffs: dict[str, ChannelDiff] = {}\n    earliest_divergence: int | None = None\n\n    for name in shared:\n        data_a = replay_a.channel(name)\n        data_b = replay_b.channel(name)\n\n        mean_a = float(np.mean(data_a))\n        mean_b = float(np.mean(data_b))\n        std_a = float(np.std(data_a))\n        std_b = float(np.std(data_b))\n\n        min_len = min(len(data_a), len(data_b))\n        max_abs_diff = float(np.max(np.abs(data_a[:min_len] - data_b[:min_len])))\n\n        div_step = _find_divergence(data_a, data_b)\n\n        channel_diffs[name] = ChannelDiff(\n            name=name,\n            mean_a=mean_a,\n            mean_b=mean_b,\n            std_a=std_a,\n            std_b=std_b,\n            max_abs_diff=max_abs_diff,\n            divergence_step=div_step,\n        )\n\n        if div_step is not None:\n            if earliest_divergence is None or div_step &lt; earliest_divergence:\n                earliest_divergence = div_step\n\n    result = CompareResult(\n        name_a=replay_a.name,\n        name_b=replay_b.name,\n        steps_a=replay_a.num_steps,\n        steps_b=replay_b.num_steps,\n        shared_channels=shared,\n        channel_diffs=channel_diffs,\n        divergence_step=earliest_divergence,\n    )\n\n    replay_a.close()\n    replay_b.close()\n    return result\n</code></pre>"},{"location":"api/compare/#roboreplay.compare.CompareResult","title":"<code>roboreplay.compare.CompareResult</code>  <code>dataclass</code>","text":"<p>Result of comparing two recordings.</p> Source code in <code>roboreplay/compare.py</code> <pre><code>@dataclass\nclass CompareResult:\n    \"\"\"Result of comparing two recordings.\"\"\"\n\n    name_a: str\n    name_b: str\n    steps_a: int\n    steps_b: int\n    shared_channels: list[str]\n    channel_diffs: dict[str, ChannelDiff] = field(default_factory=dict)\n    divergence_step: int | None = None\n\n    def summary(self) -&gt; str:\n        \"\"\"Human-readable comparison summary.\"\"\"\n        lines = []\n        lines.append(f\"Comparison: {self.name_a} vs {self.name_b}\")\n        lines.append(\"\")\n\n        # Header\n        col_a = self.name_a[:20]\n        col_b = self.name_b[:20]\n        lines.append(f\"{'':20s}  {col_a:&gt;20s}  {col_b:&gt;20s}  {'Change':&gt;10s}\")\n        lines.append(\"-\" * 76)\n\n        lines.append(f\"{'Steps':20s}  {self.steps_a:&gt;20d}  {self.steps_b:&gt;20d}\")\n\n        for name, diff in self.channel_diffs.items():\n            pct = diff.mean_change_pct\n            marker = \" \u26a0\" if abs(pct) &gt; 25 else \"\"\n            lines.append(\n                f\"{name + ' (mean)':20s}  {diff.mean_a:&gt;20.4f}  {diff.mean_b:&gt;20.4f}  \"\n                f\"{pct:&gt;+8.1f}%{marker}\"\n            )\n\n        if self.divergence_step is not None:\n            lines.append(\"\")\n            lines.append(f\"Divergence point: step {self.divergence_step}\")\n\n        return \"\\n\".join(lines)\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"CompareResult('{self.name_a}' vs '{self.name_b}', \"\n            f\"divergence={self.divergence_step})\"\n        )\n</code></pre>"},{"location":"api/compare/#roboreplay.compare.CompareResult.divergence_step","title":"<code>divergence_step = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/compare/#roboreplay.compare.CompareResult.channel_diffs","title":"<code>channel_diffs = field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/compare/#roboreplay.compare.CompareResult.shared_channels","title":"<code>shared_channels</code>  <code>instance-attribute</code>","text":""},{"location":"api/compare/#roboreplay.compare.CompareResult.summary","title":"<code>summary()</code>","text":"<p>Human-readable comparison summary.</p> Source code in <code>roboreplay/compare.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Human-readable comparison summary.\"\"\"\n    lines = []\n    lines.append(f\"Comparison: {self.name_a} vs {self.name_b}\")\n    lines.append(\"\")\n\n    # Header\n    col_a = self.name_a[:20]\n    col_b = self.name_b[:20]\n    lines.append(f\"{'':20s}  {col_a:&gt;20s}  {col_b:&gt;20s}  {'Change':&gt;10s}\")\n    lines.append(\"-\" * 76)\n\n    lines.append(f\"{'Steps':20s}  {self.steps_a:&gt;20d}  {self.steps_b:&gt;20d}\")\n\n    for name, diff in self.channel_diffs.items():\n        pct = diff.mean_change_pct\n        marker = \" \u26a0\" if abs(pct) &gt; 25 else \"\"\n        lines.append(\n            f\"{name + ' (mean)':20s}  {diff.mean_a:&gt;20.4f}  {diff.mean_b:&gt;20.4f}  \"\n            f\"{pct:&gt;+8.1f}%{marker}\"\n        )\n\n    if self.divergence_step is not None:\n        lines.append(\"\")\n        lines.append(f\"Divergence point: step {self.divergence_step}\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"api/compare/#roboreplay.compare.ChannelDiff","title":"<code>roboreplay.compare.ChannelDiff</code>  <code>dataclass</code>","text":"<p>Difference in a single channel between two recordings.</p> Source code in <code>roboreplay/compare.py</code> <pre><code>@dataclass\nclass ChannelDiff:\n    \"\"\"Difference in a single channel between two recordings.\"\"\"\n\n    name: str\n    mean_a: float\n    mean_b: float\n    std_a: float\n    std_b: float\n    max_abs_diff: float\n    divergence_step: int | None = None  # Step where they start diverging\n\n    @property\n    def mean_change_pct(self) -&gt; float:\n        if abs(self.mean_a) &lt; 1e-9:\n            return 0.0\n        return (self.mean_b - self.mean_a) / abs(self.mean_a) * 100\n</code></pre>"},{"location":"api/diagnose/","title":"Diagnose API","text":""},{"location":"api/diagnose/#roboreplay.diagnose.diagnose","title":"<code>roboreplay.diagnose.diagnose(path, drop_threshold=0.5, spike_threshold=3.0, flatline_duration=20, use_llm=False, api_key=None)</code>","text":"<p>Diagnose a recording for anomalies and failures.</p> <p>Runs statistical anomaly detection on all channels. Optionally uses an LLM for deeper analysis.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to a .rrp file.</p> required <code>drop_threshold</code> <code>float</code> <p>Sensitivity for sudden drop detection (0-1).</p> <code>0.5</code> <code>spike_threshold</code> <code>float</code> <p>Std deviations for spike detection.</p> <code>3.0</code> <code>flatline_duration</code> <code>int</code> <p>Min steps for flatline detection.</p> <code>20</code> <code>use_llm</code> <code>bool</code> <p>Whether to use LLM for enhanced diagnosis (requires API key).</p> <code>False</code> <code>api_key</code> <code>str | None</code> <p>Anthropic API key for LLM diagnosis. If None, reads from env.</p> <code>None</code> <p>Returns:</p> Type Description <code>DiagnosisResult</code> <p>DiagnosisResult with detected anomalies and summary.</p> Source code in <code>roboreplay/diagnose/__init__.py</code> <pre><code>def diagnose(\n    path: str | Path,\n    drop_threshold: float = 0.5,\n    spike_threshold: float = 3.0,\n    flatline_duration: int = 20,\n    use_llm: bool = False,\n    api_key: str | None = None,\n) -&gt; DiagnosisResult:\n    \"\"\"Diagnose a recording for anomalies and failures.\n\n    Runs statistical anomaly detection on all channels. Optionally\n    uses an LLM for deeper analysis.\n\n    Args:\n        path: Path to a .rrp file.\n        drop_threshold: Sensitivity for sudden drop detection (0-1).\n        spike_threshold: Std deviations for spike detection.\n        flatline_duration: Min steps for flatline detection.\n        use_llm: Whether to use LLM for enhanced diagnosis (requires API key).\n        api_key: Anthropic API key for LLM diagnosis. If None, reads from env.\n\n    Returns:\n        DiagnosisResult with detected anomalies and summary.\n    \"\"\"\n    replay = Replay(path)\n\n    # Load all channels\n    channels = {}\n    for name in replay.channels:\n        channels[name] = replay.channel(name)\n\n    # Run anomaly detection\n    anomalies = detect_all(\n        channels,\n        drop_threshold=drop_threshold,\n        spike_threshold=spike_threshold,\n        flatline_duration=flatline_duration,\n    )\n\n    # Build summary\n    n_failures = sum(1 for a in anomalies if a.severity &gt; 0.5)\n    n_warnings = sum(1 for a in anomalies if 0.2 &lt;= a.severity &lt;= 0.5)\n\n    if n_failures == 0 and n_warnings == 0:\n        summary = \"No anomalies detected. Recording looks clean.\"\n    else:\n        lines = []\n        if n_failures &gt; 0:\n            lines.append(f\"{n_failures} failure(s) detected:\")\n            for a in anomalies:\n                if a.severity &gt; 0.5:\n                    lines.append(f\"  \\u2022 {a.description}\")\n        if n_warnings &gt; 0:\n            lines.append(f\"{n_warnings} warning(s):\")\n            for a in anomalies:\n                if 0.2 &lt;= a.severity &lt;= 0.5:\n                    lines.append(f\"  \\u2022 {a.description}\")\n        summary = \"\\n\".join(lines)\n\n    # LLM diagnosis (optional)\n    llm_result = None\n    if use_llm:\n        from roboreplay.diagnose.llm import llm_diagnose\n\n        llm_result = llm_diagnose(\n            metadata=replay.metadata,\n            anomalies=anomalies,\n            stats=replay.stats,\n            events=replay.events,\n            api_key=api_key,\n        )\n\n    result = DiagnosisResult(\n        recording_name=replay.name,\n        num_steps=replay.num_steps,\n        anomalies=anomalies,\n        summary=summary,\n        llm_result=llm_result,\n    )\n\n    replay.close()\n    return result\n</code></pre>"},{"location":"api/diagnose/#roboreplay.diagnose.DiagnosisResult","title":"<code>roboreplay.diagnose.DiagnosisResult</code>  <code>dataclass</code>","text":"<p>Result of diagnosing a recording.</p> Source code in <code>roboreplay/diagnose/__init__.py</code> <pre><code>@dataclass\nclass DiagnosisResult:\n    \"\"\"Result of diagnosing a recording.\"\"\"\n\n    recording_name: str\n    num_steps: int\n    anomalies: list[Anomaly] = field(default_factory=list)\n    summary: str = \"\"\n    llm_result: Any = None  # LLMDiagnosisResult when use_llm=True\n\n    @property\n    def failures(self) -&gt; list[Anomaly]:\n        \"\"\"Anomalies with severity &gt; 0.5.\"\"\"\n        return [a for a in self.anomalies if a.severity &gt; 0.5]\n\n    @property\n    def warnings(self) -&gt; list[Anomaly]:\n        \"\"\"Anomalies with severity 0.2 - 0.5.\"\"\"\n        return [a for a in self.anomalies if 0.2 &lt;= a.severity &lt;= 0.5]\n\n    @property\n    def has_failures(self) -&gt; bool:\n        return len(self.failures) &gt; 0\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"DiagnosisResult(recording='{self.recording_name}', \"\n            f\"failures={len(self.failures)}, warnings={len(self.warnings)})\"\n        )\n</code></pre>"},{"location":"api/diagnose/#roboreplay.diagnose.DiagnosisResult.failures","title":"<code>failures</code>  <code>property</code>","text":"<p>Anomalies with severity &gt; 0.5.</p>"},{"location":"api/diagnose/#roboreplay.diagnose.DiagnosisResult.warnings","title":"<code>warnings</code>  <code>property</code>","text":"<p>Anomalies with severity 0.2 - 0.5.</p>"},{"location":"api/diagnose/#roboreplay.diagnose.DiagnosisResult.has_failures","title":"<code>has_failures</code>  <code>property</code>","text":""},{"location":"api/diagnose/#roboreplay.diagnose.DiagnosisResult.anomalies","title":"<code>anomalies = field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/diagnose/#roboreplay.diagnose.DiagnosisResult.summary","title":"<code>summary = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/diagnose/#roboreplay.diagnose.DiagnosisResult.llm_result","title":"<code>llm_result = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api/diagnose/#roboreplay.diagnose.anomaly.Anomaly","title":"<code>roboreplay.diagnose.anomaly.Anomaly</code>  <code>dataclass</code>","text":"<p>A detected anomaly in a recording channel.</p> Source code in <code>roboreplay/diagnose/anomaly.py</code> <pre><code>@dataclass\nclass Anomaly:\n    \"\"\"A detected anomaly in a recording channel.\"\"\"\n\n    channel: str\n    step: int\n    anomaly_type: str\n    severity: float  # 0.0 to 1.0\n    description: str\n    details: dict = field(default_factory=dict)\n\n    def __repr__(self) -&gt; str:\n        return f\"Anomaly(step={self.step}, type='{self.anomaly_type}', channel='{self.channel}')\"\n</code></pre>"},{"location":"api/diagnose/#roboreplay.diagnose.llm.LLMDiagnosisResult","title":"<code>roboreplay.diagnose.llm.LLMDiagnosisResult</code>  <code>dataclass</code>","text":"<p>Result of LLM-powered diagnosis.</p> Source code in <code>roboreplay/diagnose/llm.py</code> <pre><code>@dataclass\nclass LLMDiagnosisResult:\n    \"\"\"Result of LLM-powered diagnosis.\"\"\"\n\n    explanation: str\n    root_causes: list[str] = field(default_factory=list)\n    recommendations: list[str] = field(default_factory=list)\n    raw_response: str = \"\"\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"LLMDiagnosisResult(causes={len(self.root_causes)}, \"\n            f\"recommendations={len(self.recommendations)})\"\n        )\n</code></pre>"},{"location":"api/diagnose/#roboreplay.diagnose.llm.llm_diagnose","title":"<code>roboreplay.diagnose.llm.llm_diagnose(metadata, anomalies, stats, events, api_key=None, model='claude-sonnet-4-5-20250929')</code>","text":"<p>Run LLM-powered diagnosis on recording data.</p> <p>Parameters:</p> Name Type Description Default <code>metadata</code> <code>RecordingMetadata</code> <p>Recording metadata.</p> required <code>anomalies</code> <code>list[Anomaly]</code> <p>Detected anomalies from statistical analysis.</p> required <code>stats</code> <code>dict[str, ChannelStats]</code> <p>Per-channel statistics.</p> required <code>events</code> <code>EventLog</code> <p>Event log.</p> required <code>api_key</code> <code>str | None</code> <p>Anthropic API key. If None, reads from ANTHROPIC_API_KEY env var.</p> <code>None</code> <code>model</code> <code>str</code> <p>Claude model to use.</p> <code>'claude-sonnet-4-5-20250929'</code> <p>Returns:</p> Type Description <code>LLMDiagnosisResult</code> <p>LLMDiagnosisResult with explanation, root causes, and recommendations.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If anthropic package is not installed.</p> <code>RuntimeError</code> <p>If API call fails.</p> Source code in <code>roboreplay/diagnose/llm.py</code> <pre><code>def llm_diagnose(\n    metadata: RecordingMetadata,\n    anomalies: list[Anomaly],\n    stats: dict[str, ChannelStats],\n    events: EventLog,\n    api_key: str | None = None,\n    model: str = \"claude-sonnet-4-5-20250929\",\n) -&gt; LLMDiagnosisResult:\n    \"\"\"Run LLM-powered diagnosis on recording data.\n\n    Args:\n        metadata: Recording metadata.\n        anomalies: Detected anomalies from statistical analysis.\n        stats: Per-channel statistics.\n        events: Event log.\n        api_key: Anthropic API key. If None, reads from ANTHROPIC_API_KEY env var.\n        model: Claude model to use.\n\n    Returns:\n        LLMDiagnosisResult with explanation, root causes, and recommendations.\n\n    Raises:\n        ImportError: If anthropic package is not installed.\n        RuntimeError: If API call fails.\n    \"\"\"\n    try:\n        import anthropic\n    except ImportError:\n        raise ImportError(\n            \"The 'anthropic' package is required for LLM diagnosis. \"\n            \"Install it with: pip install roboreplay[diagnose]\"\n        )\n\n    prompt = _build_prompt(metadata, anomalies, stats, events)\n\n    try:\n        client = anthropic.Anthropic(api_key=api_key) if api_key else anthropic.Anthropic()\n        message = client.messages.create(\n            model=model,\n            max_tokens=1024,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n        )\n        response_text = message.content[0].text\n    except Exception as e:\n        raise RuntimeError(f\"LLM diagnosis failed: {e}\") from e\n\n    return _parse_response(response_text)\n</code></pre>"},{"location":"api/export/","title":"Export API","text":""},{"location":"api/export/#roboreplay.export.csv.export_csv","title":"<code>roboreplay.export.csv.export_csv(path, output_dir=None, channels=None, include_metadata=True, include_events=True)</code>","text":"<p>Export a .rrp recording to CSV files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the .rrp file.</p> required <code>output_dir</code> <code>str | Path | None</code> <p>Directory for output files. Defaults to same directory as input.</p> <code>None</code> <code>channels</code> <code>list[str] | None</code> <p>Specific channels to export. None means all.</p> <code>None</code> <code>include_metadata</code> <code>bool</code> <p>Whether to write a metadata CSV.</p> <code>True</code> <code>include_events</code> <code>bool</code> <p>Whether to write an events CSV.</p> <code>True</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>List of paths to created CSV files.</p> Source code in <code>roboreplay/export/csv.py</code> <pre><code>def export_csv(\n    path: str | Path,\n    output_dir: str | Path | None = None,\n    channels: list[str] | None = None,\n    include_metadata: bool = True,\n    include_events: bool = True,\n) -&gt; list[Path]:\n    \"\"\"Export a .rrp recording to CSV files.\n\n    Args:\n        path: Path to the .rrp file.\n        output_dir: Directory for output files. Defaults to same directory as input.\n        channels: Specific channels to export. None means all.\n        include_metadata: Whether to write a metadata CSV.\n        include_events: Whether to write an events CSV.\n\n    Returns:\n        List of paths to created CSV files.\n    \"\"\"\n    replay = Replay(path)\n    path = Path(path)\n\n    if output_dir is None:\n        out = path.parent\n    else:\n        out = Path(output_dir)\n        out.mkdir(parents=True, exist_ok=True)\n\n    name = replay.name\n    channel_names = channels if channels else replay.channels\n    created: list[Path] = []\n\n    # --- Channels CSV ---\n    channels_path = out / f\"{name}_channels.csv\"\n    _write_channels_csv(replay, channels_path, channel_names)\n    created.append(channels_path)\n\n    # --- Events CSV ---\n    if include_events and len(replay.events) &gt; 0:\n        events_path = out / f\"{name}_events.csv\"\n        _write_events_csv(replay, events_path)\n        created.append(events_path)\n\n    # --- Metadata CSV ---\n    if include_metadata:\n        meta_path = out / f\"{name}_metadata.csv\"\n        _write_metadata_csv(replay, meta_path)\n        created.append(meta_path)\n\n    replay.close()\n    return created\n</code></pre>"},{"location":"api/export/#roboreplay.export.html.export_html","title":"<code>roboreplay.export.html.export_html(path, output=None, channels=None, max_points=2000)</code>","text":"<p>Export a .rrp recording to a self-contained HTML file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to the .rrp file.</p> required <code>output</code> <code>str | Path | None</code> <p>Output HTML file path. Defaults to {name}.html next to input.</p> <code>None</code> <code>channels</code> <code>list[str] | None</code> <p>Specific channels to include. None means all.</p> <code>None</code> <code>max_points</code> <code>int</code> <p>Max data points per chart (LTTB downsampling above this).</p> <code>2000</code> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the created HTML file.</p> Source code in <code>roboreplay/export/html.py</code> <pre><code>def export_html(\n    path: str | Path,\n    output: str | Path | None = None,\n    channels: list[str] | None = None,\n    max_points: int = 2000,\n) -&gt; Path:\n    \"\"\"Export a .rrp recording to a self-contained HTML file.\n\n    Args:\n        path: Path to the .rrp file.\n        output: Output HTML file path. Defaults to {name}.html next to input.\n        channels: Specific channels to include. None means all.\n        max_points: Max data points per chart (LTTB downsampling above this).\n\n    Returns:\n        Path to the created HTML file.\n    \"\"\"\n    replay = Replay(path)\n    path = Path(path)\n\n    if output is None:\n        out_path = path.with_suffix(\".html\")\n    else:\n        out_path = Path(output)\n\n    channel_names = channels if channels else replay.channels\n\n    # Prepare chart data\n    chart_data: dict[str, dict] = {}\n    for ch_name in channel_names:\n        if ch_name not in replay.channels:\n            continue\n        data = replay.channel(ch_name)\n        if data.ndim &gt; 1:\n            data = np.linalg.norm(data, axis=-1)\n        else:\n            data = data.flatten()\n\n        indices, values = _lttb_downsample(data, max_points)\n        chart_data[ch_name] = {\"labels\": indices, \"values\": values}\n\n    # Prepare events\n    events_data = []\n    for event in replay.events.events:\n        events_data.append({\n            \"step\": event.step,\n            \"type\": event.event_type,\n            \"data\": event.data,\n        })\n\n    # Prepare stats\n    stats_data = {}\n    for name, stat in replay.stats.items():\n        if name in channel_names:\n            stats_data[name] = {\n                \"min\": round(stat.min, 4),\n                \"max\": round(stat.max, 4),\n                \"mean\": round(stat.mean, 4),\n                \"std\": round(stat.std, 4),\n            }\n\n    # Chart colors\n    colors = [\n        \"#4e79a7\", \"#f28e2b\", \"#e15759\", \"#76b7b2\",\n        \"#59a14f\", \"#edc948\", \"#b07aa1\", \"#ff9da7\",\n        \"#9c755f\", \"#bab0ac\",\n    ]\n\n    html = _generate_html(\n        name=replay.name,\n        robot=replay.robot,\n        task=replay.task,\n        num_steps=replay.num_steps,\n        channel_names=[c for c in channel_names if c in chart_data],\n        chart_data=chart_data,\n        events=events_data,\n        stats=stats_data,\n        colors=colors,\n        metadata=replay.metadata,\n    )\n\n    out_path.parent.mkdir(parents=True, exist_ok=True)\n    out_path.write_text(html, encoding=\"utf-8\")\n\n    replay.close()\n    return out_path\n</code></pre>"},{"location":"api/recorder/","title":"Recorder API","text":""},{"location":"api/recorder/#roboreplay.recorder.Recorder","title":"<code>roboreplay.recorder.Recorder</code>","text":"<p>Records robot execution data to a .rrp file.</p> <p>Accepts arbitrary numpy-compatible data channels. Schema is inferred from the first step() call. Subsequent calls must provide the same channels with matching shapes.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name for this recording (used as filename if path not specified).</p> required <code>path</code> <code>str | Path | None</code> <p>Explicit output path. If None, saves to current directory as {name}.rrp.</p> <code>None</code> <code>metadata</code> <code>dict[str, Any] | None</code> <p>Dict of recording metadata (robot, task, etc.).</p> <code>None</code> Source code in <code>roboreplay/recorder.py</code> <pre><code>class Recorder:\n    \"\"\"Records robot execution data to a .rrp file.\n\n    Accepts arbitrary numpy-compatible data channels. Schema is inferred\n    from the first step() call. Subsequent calls must provide the same\n    channels with matching shapes.\n\n    Args:\n        name: Name for this recording (used as filename if path not specified).\n        path: Explicit output path. If None, saves to current directory as {name}.rrp.\n        metadata: Dict of recording metadata (robot, task, etc.).\n    \"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        path: str | Path | None = None,\n        metadata: dict[str, Any] | None = None,\n    ) -&gt; None:\n        self.name = name\n        meta = metadata or {}\n\n        if path is None:\n            self._path = Path(f\"{name}{FILE_EXTENSION}\")\n        else:\n            self._path = Path(path)\n            if not self._path.suffix:\n                self._path = self._path.with_suffix(FILE_EXTENSION)\n\n        self._metadata = RecordingMetadata(\n            name=name,\n            robot=meta.pop(\"robot\", \"\"),\n            task=meta.pop(\"task\", \"\"),\n            user_metadata=meta,\n        )\n\n        self._writer: StreamingWriter | None = None\n        self._step_count = 0\n        self._start_time: float | None = None\n        self._started = False\n        self._saved = False\n\n    def start(self) -&gt; None:\n        \"\"\"Start recording. Opens the output file.\"\"\"\n        if self._started:\n            raise RuntimeError(\"Recording already started.\")\n\n        self._writer = StreamingWriter(self._path, self._metadata)\n        self._writer.open()\n        self._start_time = time.time()\n        self._started = True\n\n    def step(self, **channels: Any) -&gt; None:\n        \"\"\"Record one step of data.\n\n        Pass each data channel as a keyword argument. Values must be\n        numpy arrays or array-like (lists, floats, etc.).\n\n        On the first call, this defines the recording schema.\n        Subsequent calls must provide the same channel names.\n\n        Args:\n            **channels: Keyword arguments mapping channel names to data.\n                        e.g. step(state=np.array([...]), action=np.array([...]), reward=0.5)\n\n        Example:\n            rec.step(\n                state=env.get_state(),\n                action=policy_output,\n                reward=reward,\n                gripper_force=np.array([8.2]),\n            )\n        \"\"\"\n        if not self._started:\n            self.start()\n\n        if not channels:\n            raise ValueError(\"step() requires at least one channel. e.g. rec.step(state=arr)\")\n\n        # Convert all values to numpy arrays\n        np_channels: dict[str, np.ndarray] = {}\n        for name, value in channels.items():\n            arr = np.asarray(value, dtype=np.float32)\n            # Scalars become 1D arrays\n            if arr.ndim == 0:\n                arr = arr.reshape(1)\n            np_channels[name] = arr\n\n        assert self._writer is not None\n        self._writer.write_step(np_channels)\n        self._step_count += 1\n\n    def mark_event(self, event_type: str, data: dict[str, Any] | None = None) -&gt; None:\n        \"\"\"Mark an event at the current step.\n\n        Events are timestamped markers that annotate the recording.\n        Use them to flag milestones, failures, phase transitions, etc.\n\n        Args:\n            event_type: Type of event (e.g. \"failure\", \"grasp_start\", \"episode_end\").\n            data: Optional dict of event-specific data.\n\n        Example:\n            rec.mark_event(\"grasp_slip\", {\"force_at_slip\": 1.2, \"expected_force\": 8.0})\n        \"\"\"\n        if not self._started:\n            raise RuntimeError(\"Cannot mark events before recording starts. Call start() first.\")\n\n        assert self._writer is not None\n        self._writer.write_event(self._step_count, event_type, data)\n\n    def save(self) -&gt; Path:\n        \"\"\"Finalize and save the recording.\n\n        Returns:\n            Path to the saved .rrp file.\n        \"\"\"\n        if not self._started:\n            raise RuntimeError(\"Nothing to save \u2014 recording was never started.\")\n        if self._saved:\n            raise RuntimeError(\"Recording already saved.\")\n\n        assert self._writer is not None\n        self._writer.close()\n        self._saved = True\n        return self._path\n\n    @property\n    def num_steps(self) -&gt; int:\n        \"\"\"Number of steps recorded so far.\"\"\"\n        return self._step_count\n\n    @property\n    def duration(self) -&gt; float:\n        \"\"\"Elapsed time since recording started, in seconds.\"\"\"\n        if self._start_time is None:\n            return 0.0\n        return time.time() - self._start_time\n\n    @property\n    def path(self) -&gt; Path:\n        \"\"\"Output file path.\"\"\"\n        return self._path\n\n    # Context manager support\n    def __enter__(self) -&gt; Recorder:\n        self.start()\n        return self\n\n    def __exit__(self, *args: Any) -&gt; None:\n        if self._started and not self._saved:\n            self.save()\n\n    def __repr__(self) -&gt; str:\n        if self._started and not self._saved:\n            status = \"recording\"\n        elif self._saved:\n            status = \"saved\"\n        else:\n            status = \"idle\"\n        return f\"Recorder(name='{self.name}', steps={self._step_count}, status={status})\"\n</code></pre>"},{"location":"api/recorder/#roboreplay.recorder.Recorder.num_steps","title":"<code>num_steps</code>  <code>property</code>","text":"<p>Number of steps recorded so far.</p>"},{"location":"api/recorder/#roboreplay.recorder.Recorder.duration","title":"<code>duration</code>  <code>property</code>","text":"<p>Elapsed time since recording started, in seconds.</p>"},{"location":"api/recorder/#roboreplay.recorder.Recorder.path","title":"<code>path</code>  <code>property</code>","text":"<p>Output file path.</p>"},{"location":"api/recorder/#roboreplay.recorder.Recorder.__init__","title":"<code>__init__(name, path=None, metadata=None)</code>","text":"Source code in <code>roboreplay/recorder.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    path: str | Path | None = None,\n    metadata: dict[str, Any] | None = None,\n) -&gt; None:\n    self.name = name\n    meta = metadata or {}\n\n    if path is None:\n        self._path = Path(f\"{name}{FILE_EXTENSION}\")\n    else:\n        self._path = Path(path)\n        if not self._path.suffix:\n            self._path = self._path.with_suffix(FILE_EXTENSION)\n\n    self._metadata = RecordingMetadata(\n        name=name,\n        robot=meta.pop(\"robot\", \"\"),\n        task=meta.pop(\"task\", \"\"),\n        user_metadata=meta,\n    )\n\n    self._writer: StreamingWriter | None = None\n    self._step_count = 0\n    self._start_time: float | None = None\n    self._started = False\n    self._saved = False\n</code></pre>"},{"location":"api/recorder/#roboreplay.recorder.Recorder.start","title":"<code>start()</code>","text":"<p>Start recording. Opens the output file.</p> Source code in <code>roboreplay/recorder.py</code> <pre><code>def start(self) -&gt; None:\n    \"\"\"Start recording. Opens the output file.\"\"\"\n    if self._started:\n        raise RuntimeError(\"Recording already started.\")\n\n    self._writer = StreamingWriter(self._path, self._metadata)\n    self._writer.open()\n    self._start_time = time.time()\n    self._started = True\n</code></pre>"},{"location":"api/recorder/#roboreplay.recorder.Recorder.step","title":"<code>step(**channels)</code>","text":"<p>Record one step of data.</p> <p>Pass each data channel as a keyword argument. Values must be numpy arrays or array-like (lists, floats, etc.).</p> <p>On the first call, this defines the recording schema. Subsequent calls must provide the same channel names.</p> <p>Parameters:</p> Name Type Description Default <code>**channels</code> <code>Any</code> <p>Keyword arguments mapping channel names to data.         e.g. step(state=np.array([...]), action=np.array([...]), reward=0.5)</p> <code>{}</code> Example <p>rec.step(     state=env.get_state(),     action=policy_output,     reward=reward,     gripper_force=np.array([8.2]), )</p> Source code in <code>roboreplay/recorder.py</code> <pre><code>def step(self, **channels: Any) -&gt; None:\n    \"\"\"Record one step of data.\n\n    Pass each data channel as a keyword argument. Values must be\n    numpy arrays or array-like (lists, floats, etc.).\n\n    On the first call, this defines the recording schema.\n    Subsequent calls must provide the same channel names.\n\n    Args:\n        **channels: Keyword arguments mapping channel names to data.\n                    e.g. step(state=np.array([...]), action=np.array([...]), reward=0.5)\n\n    Example:\n        rec.step(\n            state=env.get_state(),\n            action=policy_output,\n            reward=reward,\n            gripper_force=np.array([8.2]),\n        )\n    \"\"\"\n    if not self._started:\n        self.start()\n\n    if not channels:\n        raise ValueError(\"step() requires at least one channel. e.g. rec.step(state=arr)\")\n\n    # Convert all values to numpy arrays\n    np_channels: dict[str, np.ndarray] = {}\n    for name, value in channels.items():\n        arr = np.asarray(value, dtype=np.float32)\n        # Scalars become 1D arrays\n        if arr.ndim == 0:\n            arr = arr.reshape(1)\n        np_channels[name] = arr\n\n    assert self._writer is not None\n    self._writer.write_step(np_channels)\n    self._step_count += 1\n</code></pre>"},{"location":"api/recorder/#roboreplay.recorder.Recorder.mark_event","title":"<code>mark_event(event_type, data=None)</code>","text":"<p>Mark an event at the current step.</p> <p>Events are timestamped markers that annotate the recording. Use them to flag milestones, failures, phase transitions, etc.</p> <p>Parameters:</p> Name Type Description Default <code>event_type</code> <code>str</code> <p>Type of event (e.g. \"failure\", \"grasp_start\", \"episode_end\").</p> required <code>data</code> <code>dict[str, Any] | None</code> <p>Optional dict of event-specific data.</p> <code>None</code> Example <p>rec.mark_event(\"grasp_slip\", {\"force_at_slip\": 1.2, \"expected_force\": 8.0})</p> Source code in <code>roboreplay/recorder.py</code> <pre><code>def mark_event(self, event_type: str, data: dict[str, Any] | None = None) -&gt; None:\n    \"\"\"Mark an event at the current step.\n\n    Events are timestamped markers that annotate the recording.\n    Use them to flag milestones, failures, phase transitions, etc.\n\n    Args:\n        event_type: Type of event (e.g. \"failure\", \"grasp_start\", \"episode_end\").\n        data: Optional dict of event-specific data.\n\n    Example:\n        rec.mark_event(\"grasp_slip\", {\"force_at_slip\": 1.2, \"expected_force\": 8.0})\n    \"\"\"\n    if not self._started:\n        raise RuntimeError(\"Cannot mark events before recording starts. Call start() first.\")\n\n    assert self._writer is not None\n    self._writer.write_event(self._step_count, event_type, data)\n</code></pre>"},{"location":"api/recorder/#roboreplay.recorder.Recorder.save","title":"<code>save()</code>","text":"<p>Finalize and save the recording.</p> <p>Returns:</p> Type Description <code>Path</code> <p>Path to the saved .rrp file.</p> Source code in <code>roboreplay/recorder.py</code> <pre><code>def save(self) -&gt; Path:\n    \"\"\"Finalize and save the recording.\n\n    Returns:\n        Path to the saved .rrp file.\n    \"\"\"\n    if not self._started:\n        raise RuntimeError(\"Nothing to save \u2014 recording was never started.\")\n    if self._saved:\n        raise RuntimeError(\"Recording already saved.\")\n\n    assert self._writer is not None\n    self._writer.close()\n    self._saved = True\n    return self._path\n</code></pre>"},{"location":"api/replay/","title":"Replay API","text":""},{"location":"api/replay/#roboreplay.replay.Replay","title":"<code>roboreplay.replay.Replay</code>","text":"<p>Read and navigate a .rrp recording.</p> <p>Provides indexing, slicing, channel access, event queries, and basic visualization.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path to a .rrp file.</p> required Source code in <code>roboreplay/replay.py</code> <pre><code>class Replay:\n    \"\"\"Read and navigate a .rrp recording.\n\n    Provides indexing, slicing, channel access, event queries,\n    and basic visualization.\n\n    Args:\n        path: Path to a .rrp file.\n    \"\"\"\n\n    def __init__(self, path: str | Path) -&gt; None:\n        self._reader = Reader(path)\n        self._reader.open()\n\n    def close(self) -&gt; None:\n        \"\"\"Close the underlying file.\"\"\"\n        self._reader.close()\n\n    def __enter__(self) -&gt; Replay:\n        return self\n\n    def __exit__(self, *args: Any) -&gt; None:\n        self.close()\n\n    # --- Properties ---\n\n    @property\n    def metadata(self) -&gt; RecordingMetadata:\n        \"\"\"Recording metadata (name, robot, task, system info, etc.).\"\"\"\n        return self._reader.metadata\n\n    @property\n    def schema(self) -&gt; RecordingSchema:\n        \"\"\"Schema describing all recorded channels.\"\"\"\n        return self._reader.schema\n\n    @property\n    def events(self) -&gt; EventLog:\n        \"\"\"All events marked during recording.\"\"\"\n        return self._reader.events\n\n    @property\n    def stats(self) -&gt; dict[str, ChannelStats]:\n        \"\"\"Pre-computed statistics per channel.\"\"\"\n        return self._reader.stats\n\n    @property\n    def channels(self) -&gt; list[str]:\n        \"\"\"List of recorded channel names.\"\"\"\n        return self._reader.channel_names\n\n    @property\n    def num_steps(self) -&gt; int:\n        \"\"\"Total number of recorded steps.\"\"\"\n        return self._reader.num_steps\n\n    @property\n    def name(self) -&gt; str:\n        return self.metadata.name\n\n    @property\n    def robot(self) -&gt; str:\n        return self.metadata.robot\n\n    @property\n    def task(self) -&gt; str:\n        return self.metadata.task\n\n    # --- Data Access ---\n\n    def channel(self, name: str, start: int = 0, end: int | None = None) -&gt; np.ndarray:\n        \"\"\"Get data for a single channel.\n\n        Args:\n            name: Channel name.\n            start: Start step (inclusive). Default 0.\n            end: End step (exclusive). Default None (all steps).\n\n        Returns:\n            numpy array of shape [steps, *channel_shape]\n        \"\"\"\n        return self._reader.get_channel(name, start, end)\n\n    @overload\n    def __getitem__(self, key: int) -&gt; dict[str, np.ndarray]: ...\n\n    @overload\n    def __getitem__(self, key: slice) -&gt; dict[str, np.ndarray]: ...\n\n    def __getitem__(self, key: int | slice) -&gt; dict[str, np.ndarray]:\n        \"\"\"Index or slice the recording.\n\n        replay[step] \u2192 dict of all channel values at that step\n        replay[start:end] \u2192 dict of all channel arrays over range\n        \"\"\"\n        if isinstance(key, int):\n            if key &lt; 0:\n                key = self.num_steps + key\n            return self._reader.get_step(key)\n        elif isinstance(key, slice):\n            start, end, _ = key.indices(self.num_steps)\n            return self._reader.get_slice(start, end)\n        else:\n            raise TypeError(f\"Invalid index type: {type(key)}. Use int or slice.\")\n\n    # --- Visualization ---\n\n    def plot(self, channel_name: str, start: int = 0, end: int | None = None) -&gt; Any:\n        \"\"\"Plot a channel over time using matplotlib.\n\n        Args:\n            channel_name: Name of the channel to plot.\n            start: Start step.\n            end: End step.\n\n        Returns:\n            matplotlib Figure object.\n\n        Raises:\n            ImportError: If matplotlib is not installed.\n        \"\"\"\n        try:\n            import matplotlib.pyplot as plt\n        except ImportError:\n            raise ImportError(\n                \"matplotlib is required for plotting. \"\n                \"Install it with: pip install roboreplay[viz]\"\n            )\n\n        data = self.channel(channel_name, start, end)\n        fig, ax = plt.subplots(figsize=(12, 4))\n\n        steps = np.arange(start, start + len(data))\n\n        if data.ndim == 1 or (data.ndim == 2 and data.shape[1] == 1):\n            # Scalar channel\n            values = data.flatten()\n            ax.plot(steps, values, linewidth=0.8)\n        elif data.ndim == 2:\n            # Multi-dimensional channel \u2014 plot each dimension\n            for dim in range(data.shape[1]):\n                ax.plot(steps, data[:, dim], linewidth=0.8, label=f\"dim_{dim}\")\n            ax.legend(fontsize=8)\n        else:\n            raise ValueError(f\"Cannot plot channel with {data.ndim} dimensions\")\n\n        # Mark events on the plot\n        for event in self.events.events:\n            if start &lt;= event.step &lt; (end or self.num_steps):\n                ax.axvline(x=event.step, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=0.8)\n                ax.text(\n                    event.step, ax.get_ylim()[1] * 0.95,\n                    event.event_type, fontsize=7, color=\"red\",\n                    rotation=45, ha=\"left\", va=\"top\",\n                )\n\n        ax.set_xlabel(\"Step\")\n        ax.set_ylabel(channel_name)\n        ax.set_title(f\"{self.name} \u2014 {channel_name}\")\n        ax.grid(True, alpha=0.3)\n        fig.tight_layout()\n\n        return fig\n\n    # --- Display ---\n\n    def summary(self) -&gt; str:\n        \"\"\"Generate a human-readable summary string.\"\"\"\n        lines = []\n        lines.append(f\"Recording: {self.name}\")\n        if self.robot:\n            lines.append(f\"Robot: {self.robot}\")\n        if self.task:\n            lines.append(f\"Task: {self.task}\")\n        lines.append(f\"Steps: {self.num_steps}\")\n        lines.append(f\"Channels: {', '.join(self.channels)}\")\n\n        if self.stats:\n            lines.append(\"Channel Stats:\")\n            for name, stat in self.stats.items():\n                lines.append(\n                    f\"  {name}: min={stat.min:.4f}, max={stat.max:.4f}, \"\n                    f\"mean={stat.mean:.4f}, std={stat.std:.4f}\"\n                )\n\n        n_events = len(self.events)\n        if n_events &gt; 0:\n            lines.append(f\"Events: {n_events}\")\n            for event in self.events.events[:5]:  # Show first 5\n                lines.append(f\"  [{event.step}] {event.event_type}: {event.data}\")\n            if n_events &gt; 5:\n                lines.append(f\"  ... and {n_events - 5} more\")\n\n        return \"\\n\".join(lines)\n\n    def __repr__(self) -&gt; str:\n        return (\n            f\"Replay(name='{self.name}', robot='{self.robot}', \"\n            f\"steps={self.num_steps}, channels={self.channels})\"\n        )\n\n    def __str__(self) -&gt; str:\n        return self.summary()\n\n    def __len__(self) -&gt; int:\n        return self.num_steps\n</code></pre>"},{"location":"api/replay/#roboreplay.replay.Replay.metadata","title":"<code>metadata</code>  <code>property</code>","text":"<p>Recording metadata (name, robot, task, system info, etc.).</p>"},{"location":"api/replay/#roboreplay.replay.Replay.schema","title":"<code>schema</code>  <code>property</code>","text":"<p>Schema describing all recorded channels.</p>"},{"location":"api/replay/#roboreplay.replay.Replay.events","title":"<code>events</code>  <code>property</code>","text":"<p>All events marked during recording.</p>"},{"location":"api/replay/#roboreplay.replay.Replay.stats","title":"<code>stats</code>  <code>property</code>","text":"<p>Pre-computed statistics per channel.</p>"},{"location":"api/replay/#roboreplay.replay.Replay.channels","title":"<code>channels</code>  <code>property</code>","text":"<p>List of recorded channel names.</p>"},{"location":"api/replay/#roboreplay.replay.Replay.num_steps","title":"<code>num_steps</code>  <code>property</code>","text":"<p>Total number of recorded steps.</p>"},{"location":"api/replay/#roboreplay.replay.Replay.__init__","title":"<code>__init__(path)</code>","text":"Source code in <code>roboreplay/replay.py</code> <pre><code>def __init__(self, path: str | Path) -&gt; None:\n    self._reader = Reader(path)\n    self._reader.open()\n</code></pre>"},{"location":"api/replay/#roboreplay.replay.Replay.close","title":"<code>close()</code>","text":"<p>Close the underlying file.</p> Source code in <code>roboreplay/replay.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the underlying file.\"\"\"\n    self._reader.close()\n</code></pre>"},{"location":"api/replay/#roboreplay.replay.Replay.channel","title":"<code>channel(name, start=0, end=None)</code>","text":"<p>Get data for a single channel.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Channel name.</p> required <code>start</code> <code>int</code> <p>Start step (inclusive). Default 0.</p> <code>0</code> <code>end</code> <code>int | None</code> <p>End step (exclusive). Default None (all steps).</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy array of shape [steps, *channel_shape]</p> Source code in <code>roboreplay/replay.py</code> <pre><code>def channel(self, name: str, start: int = 0, end: int | None = None) -&gt; np.ndarray:\n    \"\"\"Get data for a single channel.\n\n    Args:\n        name: Channel name.\n        start: Start step (inclusive). Default 0.\n        end: End step (exclusive). Default None (all steps).\n\n    Returns:\n        numpy array of shape [steps, *channel_shape]\n    \"\"\"\n    return self._reader.get_channel(name, start, end)\n</code></pre>"},{"location":"api/replay/#roboreplay.replay.Replay.__getitem__","title":"<code>__getitem__(key)</code>","text":"<pre><code>__getitem__(key: int) -&gt; dict[str, np.ndarray]\n</code></pre><pre><code>__getitem__(key: slice) -&gt; dict[str, np.ndarray]\n</code></pre> <p>Index or slice the recording.</p> <p>replay[step] \u2192 dict of all channel values at that step replay[start:end] \u2192 dict of all channel arrays over range</p> Source code in <code>roboreplay/replay.py</code> <pre><code>def __getitem__(self, key: int | slice) -&gt; dict[str, np.ndarray]:\n    \"\"\"Index or slice the recording.\n\n    replay[step] \u2192 dict of all channel values at that step\n    replay[start:end] \u2192 dict of all channel arrays over range\n    \"\"\"\n    if isinstance(key, int):\n        if key &lt; 0:\n            key = self.num_steps + key\n        return self._reader.get_step(key)\n    elif isinstance(key, slice):\n        start, end, _ = key.indices(self.num_steps)\n        return self._reader.get_slice(start, end)\n    else:\n        raise TypeError(f\"Invalid index type: {type(key)}. Use int or slice.\")\n</code></pre>"},{"location":"api/replay/#roboreplay.replay.Replay.plot","title":"<code>plot(channel_name, start=0, end=None)</code>","text":"<p>Plot a channel over time using matplotlib.</p> <p>Parameters:</p> Name Type Description Default <code>channel_name</code> <code>str</code> <p>Name of the channel to plot.</p> required <code>start</code> <code>int</code> <p>Start step.</p> <code>0</code> <code>end</code> <code>int | None</code> <p>End step.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>matplotlib Figure object.</p> <p>Raises:</p> Type Description <code>ImportError</code> <p>If matplotlib is not installed.</p> Source code in <code>roboreplay/replay.py</code> <pre><code>def plot(self, channel_name: str, start: int = 0, end: int | None = None) -&gt; Any:\n    \"\"\"Plot a channel over time using matplotlib.\n\n    Args:\n        channel_name: Name of the channel to plot.\n        start: Start step.\n        end: End step.\n\n    Returns:\n        matplotlib Figure object.\n\n    Raises:\n        ImportError: If matplotlib is not installed.\n    \"\"\"\n    try:\n        import matplotlib.pyplot as plt\n    except ImportError:\n        raise ImportError(\n            \"matplotlib is required for plotting. \"\n            \"Install it with: pip install roboreplay[viz]\"\n        )\n\n    data = self.channel(channel_name, start, end)\n    fig, ax = plt.subplots(figsize=(12, 4))\n\n    steps = np.arange(start, start + len(data))\n\n    if data.ndim == 1 or (data.ndim == 2 and data.shape[1] == 1):\n        # Scalar channel\n        values = data.flatten()\n        ax.plot(steps, values, linewidth=0.8)\n    elif data.ndim == 2:\n        # Multi-dimensional channel \u2014 plot each dimension\n        for dim in range(data.shape[1]):\n            ax.plot(steps, data[:, dim], linewidth=0.8, label=f\"dim_{dim}\")\n        ax.legend(fontsize=8)\n    else:\n        raise ValueError(f\"Cannot plot channel with {data.ndim} dimensions\")\n\n    # Mark events on the plot\n    for event in self.events.events:\n        if start &lt;= event.step &lt; (end or self.num_steps):\n            ax.axvline(x=event.step, color=\"red\", linestyle=\"--\", alpha=0.5, linewidth=0.8)\n            ax.text(\n                event.step, ax.get_ylim()[1] * 0.95,\n                event.event_type, fontsize=7, color=\"red\",\n                rotation=45, ha=\"left\", va=\"top\",\n            )\n\n    ax.set_xlabel(\"Step\")\n    ax.set_ylabel(channel_name)\n    ax.set_title(f\"{self.name} \u2014 {channel_name}\")\n    ax.grid(True, alpha=0.3)\n    fig.tight_layout()\n\n    return fig\n</code></pre>"},{"location":"api/replay/#roboreplay.replay.Replay.summary","title":"<code>summary()</code>","text":"<p>Generate a human-readable summary string.</p> Source code in <code>roboreplay/replay.py</code> <pre><code>def summary(self) -&gt; str:\n    \"\"\"Generate a human-readable summary string.\"\"\"\n    lines = []\n    lines.append(f\"Recording: {self.name}\")\n    if self.robot:\n        lines.append(f\"Robot: {self.robot}\")\n    if self.task:\n        lines.append(f\"Task: {self.task}\")\n    lines.append(f\"Steps: {self.num_steps}\")\n    lines.append(f\"Channels: {', '.join(self.channels)}\")\n\n    if self.stats:\n        lines.append(\"Channel Stats:\")\n        for name, stat in self.stats.items():\n            lines.append(\n                f\"  {name}: min={stat.min:.4f}, max={stat.max:.4f}, \"\n                f\"mean={stat.mean:.4f}, std={stat.std:.4f}\"\n            )\n\n    n_events = len(self.events)\n    if n_events &gt; 0:\n        lines.append(f\"Events: {n_events}\")\n        for event in self.events.events[:5]:  # Show first 5\n            lines.append(f\"  [{event.step}] {event.event_type}: {event.data}\")\n        if n_events &gt; 5:\n            lines.append(f\"  ... and {n_events - 5} more\")\n\n    return \"\\n\".join(lines)\n</code></pre>"},{"location":"examples/batch-analysis/","title":"Batch Analysis Example","text":"<p>Generates 5 recordings with varying conditions, runs batch diagnosis, and exports to CSV.</p>"},{"location":"examples/batch-analysis/#run","title":"Run","text":"<pre><code>python examples/batch_analysis.py\n</code></pre> <p>No external dependencies required.</p>"},{"location":"examples/batch-analysis/#what-it-does","title":"What It Does","text":"<ol> <li> <p>Generates 5 recordings with different parameters:</p> <ul> <li><code>run_clean_1</code> \u2014 Low noise, no failure</li> <li><code>run_clean_2</code> \u2014 Medium noise, no failure</li> <li><code>run_noisy</code> \u2014 High noise, no failure</li> <li><code>run_fail_early</code> \u2014 Failure at step 80</li> <li><code>run_fail_late</code> \u2014 Failure at step 160</li> </ul> </li> <li> <p>Batch diagnosis \u2014 Runs <code>diagnose()</code> on all recordings, prints summary table</p> </li> <li> <p>CSV export \u2014 Exports all recordings to CSV for further analysis</p> </li> </ol>"},{"location":"examples/batch-analysis/#output-structure","title":"Output Structure","text":"<pre><code>batch_output/\n\u251c\u2500\u2500 run_clean_1.rrp\n\u251c\u2500\u2500 run_clean_2.rrp\n\u251c\u2500\u2500 run_noisy.rrp\n\u251c\u2500\u2500 run_fail_early.rrp\n\u251c\u2500\u2500 run_fail_late.rrp\n\u2514\u2500\u2500 csv/\n    \u251c\u2500\u2500 run_clean_1_channels.csv\n    \u251c\u2500\u2500 run_clean_1_metadata.csv\n    \u251c\u2500\u2500 ...\n</code></pre>"},{"location":"examples/batch-analysis/#use-case","title":"Use Case","text":"<p>This pattern is useful for:</p> <ul> <li>Comparing policy versions across multiple seeds</li> <li>Automated test pipelines that check for regressions</li> <li>Data collection campaigns with quality validation</li> </ul>"},{"location":"examples/cartpole/","title":"CartPole Example","text":"<p>Demonstrates using <code>roboreplay.wrap()</code> with Gymnasium's CartPole environment.</p>"},{"location":"examples/cartpole/#requirements","title":"Requirements","text":"<pre><code>pip install roboreplay[gym]\n</code></pre>"},{"location":"examples/cartpole/#run","title":"Run","text":"<pre><code>python examples/gymnasium_cartpole.py\n</code></pre>"},{"location":"examples/cartpole/#what-it-does","title":"What It Does","text":"<ol> <li>Wraps <code>CartPole-v1</code> with <code>roboreplay.wrap()</code></li> <li>Runs 5 episodes with random actions</li> <li>Replays and inspects the recording</li> <li>Runs diagnosis</li> </ol>"},{"location":"examples/cartpole/#recorded-channels","title":"Recorded Channels","text":"<ul> <li><code>observation</code> \u2014 Cart position, velocity, pole angle, angular velocity</li> <li><code>action</code> \u2014 Discrete action (left/right, stored as float)</li> <li><code>reward</code> \u2014 Step reward (always 1.0 for CartPole)</li> </ul>"},{"location":"examples/cartpole/#automatic-events","title":"Automatic Events","text":"<ul> <li><code>episode_reset</code> \u2014 On each <code>reset()</code> call</li> <li><code>episode_terminated</code> \u2014 On each episode termination</li> <li><code>recording_end</code> \u2014 On <code>close()</code>, with total counts</li> </ul>"},{"location":"examples/custom-robot/","title":"Custom Robot Example","text":"<p>Simulates a 6-DOF robot arm with two runs (success and failure), then compares them.</p>"},{"location":"examples/custom-robot/#run","title":"Run","text":"<pre><code>python examples/custom_robot.py\n</code></pre> <p>No external dependencies required.</p>"},{"location":"examples/custom-robot/#what-it-does","title":"What It Does","text":"<ol> <li>Records a success run \u2014 smooth reaching task</li> <li>Records a failure run \u2014 injects a joint limit violation at step 150</li> <li>Compares both recordings to find the divergence point</li> <li>Diagnoses the failure run</li> </ol>"},{"location":"examples/custom-robot/#channels-recorded","title":"Channels Recorded","text":"<ul> <li><code>joint_positions</code> \u2014 6-DOF joint angles</li> <li><code>joint_velocities</code> \u2014 6-DOF velocities</li> <li><code>ee_position</code> \u2014 End-effector position (simplified FK)</li> <li><code>target_error</code> \u2014 Distance to target</li> <li><code>torque</code> \u2014 Estimated joint torques</li> <li><code>reward</code> \u2014 Negative error as reward</li> </ul>"},{"location":"examples/custom-robot/#key-takeaway","title":"Key Takeaway","text":"<p>The comparison finds exactly where the two runs diverge, making it easy to identify what went wrong and when.</p>"},{"location":"examples/mujoco-panda/","title":"MuJoCo Panda Reaching Task","text":"<p>A real MuJoCo simulation example using the Franka Emika Panda robot arm performing a reaching task with a PD controller.</p>"},{"location":"examples/mujoco-panda/#requirements","title":"Requirements","text":"<pre><code>pip install roboreplay[mujoco]\n</code></pre>"},{"location":"examples/mujoco-panda/#run","title":"Run","text":"<pre><code>python examples/mujoco_panda.py\n</code></pre>"},{"location":"examples/mujoco-panda/#what-it-does","title":"What It Does","text":"<ol> <li>Loads a 7-DOF Panda arm \u2014 Simplified MJCF model with joint limits and actuator ranges</li> <li>PD controller \u2014 Tracks a target joint configuration to reach a 3D target position</li> <li>Records at 50 Hz \u2014 Every 10th physics step (timestep = 0.002s)</li> <li>Reaches target \u2014 End-effector converges to within 5cm of the target</li> </ol>"},{"location":"examples/mujoco-panda/#channels-recorded","title":"Channels Recorded","text":"<ul> <li><code>qpos</code> \u2014 7-DOF joint positions (radians)</li> <li><code>qvel</code> \u2014 7-DOF joint velocities (rad/s)</li> <li><code>ctrl</code> \u2014 7-DOF control torques (Nm)</li> <li><code>ee_position</code> \u2014 End-effector XYZ position (meters)</li> <li><code>ee_error</code> \u2014 Scalar distance to target (meters)</li> </ul>"},{"location":"examples/mujoco-panda/#events","title":"Events","text":"<ul> <li><code>phase_start</code> \u2014 Start of reaching phase with target position</li> <li><code>target_reached</code> \u2014 End-effector within 5cm of target</li> <li><code>episode_end</code> \u2014 End of simulation with success flag</li> </ul>"},{"location":"examples/mujoco-panda/#key-code","title":"Key Code","text":"<p>The PD controller computes torques from joint position error:</p> <pre><code>q_error = TARGET_QPOS - data.qpos[:7]\nctrl = KP * q_error - KD * data.qvel[:7]\ndata.ctrl[:7] = np.clip(ctrl, -ctrl_range, ctrl_range)\n</code></pre> <p>Recording happens every 10th physics step:</p> <pre><code>rec.step(\n    qpos=data.qpos[:7].copy(),\n    qvel=data.qvel[:7].copy(),\n    ctrl=data.ctrl[:7].copy(),\n    ee_position=ee_pos,\n    ee_error=np.array([ee_error]),\n)\n</code></pre>"},{"location":"examples/mujoco-panda/#after-recording","title":"After Recording","text":"<pre><code>roboreplay info mujoco_panda_reach.rrp\nroboreplay diagnose mujoco_panda_reach.rrp\nroboreplay export mujoco_panda_reach.rrp --format html\n</code></pre> <p>The diagnosis should show a clean run with the end-effector converging smoothly to the target.</p>"},{"location":"examples/pick-place/","title":"Pick and Place Demo","text":"<p>The flagship example simulates a 7-DOF robot arm performing a pick-and-place task with a realistic gripper slip failure.</p>"},{"location":"examples/pick-place/#run","title":"Run","text":"<pre><code>python examples/simulated_pick_place.py\n</code></pre>"},{"location":"examples/pick-place/#what-it-does","title":"What It Does","text":"<ol> <li>Approach (steps 0-99) \u2014 Robot moves from home to above the object</li> <li>Grasp (steps 100-149) \u2014 Gripper closes, force builds to ~8.5N</li> <li>Lift (steps 150-249) \u2014 Lifts object; slip failure at step 200 (force drops from 8N to 1.2N)</li> <li>Recovery (steps 250-299) \u2014 Robot attempts recovery</li> </ol>"},{"location":"examples/pick-place/#channels-recorded","title":"Channels Recorded","text":"<ul> <li><code>joint_positions</code> \u2014 7-DOF joint angles</li> <li><code>action</code> \u2014 7-DOF action commands</li> <li><code>gripper_width</code> \u2014 Gripper opening</li> <li><code>gripper_force</code> \u2014 Gripper force (key signal for failure)</li> <li><code>ee_position</code> \u2014 End-effector position</li> <li><code>reward</code> \u2014 Scalar reward</li> </ul>"},{"location":"examples/pick-place/#events","title":"Events","text":"<ul> <li><code>phase_start</code> \u2014 Phase transitions</li> <li><code>grasp_acquired</code> \u2014 Successful grasp</li> <li><code>failure</code> \u2014 Grasp slip at step 200</li> <li><code>episode_end</code> \u2014 End of episode</li> </ul>"},{"location":"examples/pick-place/#after-recording","title":"After Recording","text":"<pre><code>roboreplay info pick_place_demo.rrp\nroboreplay diagnose pick_place_demo.rrp\nroboreplay export pick_place_demo.rrp --format html\n</code></pre> <p>The diagnosis should detect the sudden drop in <code>gripper_force</code> at step 200.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#basic-install","title":"Basic Install","text":"<pre><code>pip install roboreplay\n</code></pre> <p>This installs core functionality: recording, replaying, diagnosis, comparison, and CLI.</p>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>RoboReplay has several optional dependency groups:</p> <pre><code># Visualization (matplotlib)\npip install roboreplay[viz]\n\n# Gymnasium wrapper\npip install roboreplay[gym]\n\n# LLM-powered diagnosis (requires Anthropic API key)\npip install roboreplay[diagnose]\n\n# Documentation tools\npip install roboreplay[docs]\n\n# Development (testing, linting, type checking)\npip install roboreplay[dev]\n\n# Everything\npip install roboreplay[all]\n</code></pre>"},{"location":"getting-started/installation/#development-setup","title":"Development Setup","text":"<pre><code>git clone https://github.com/gow/roboreplay.git\ncd roboreplay\npip install -e \".[dev]\"\npytest tests/ -v\n</code></pre>"},{"location":"getting-started/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>NumPy &gt;= 1.24</li> <li>h5py &gt;= 3.9</li> <li>Click &gt;= 8.0</li> <li>Rich &gt;= 13.0</li> <li>Pydantic &gt;= 2.0</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quickstart","text":""},{"location":"getting-started/quickstart/#record-your-first-session","title":"Record Your First Session","text":"<pre><code>import numpy as np\nfrom roboreplay import Recorder\n\nwith Recorder(\"my_first_recording\", metadata={\"robot\": \"my_robot\"}) as rec:\n    for i in range(100):\n        rec.step(\n            position=np.random.randn(3),\n            velocity=np.random.randn(3),\n            reward=float(i) / 100,\n        )\n        if i == 50:\n            rec.mark_event(\"halfway\", {\"note\": \"midpoint reached\"})\n</code></pre> <p>This creates <code>my_first_recording.rrp</code> in the current directory.</p>"},{"location":"getting-started/quickstart/#replay-and-inspect","title":"Replay and Inspect","text":"<pre><code>from roboreplay import Replay\n\nr = Replay(\"my_first_recording.rrp\")\nprint(r)                    # Summary\nprint(r.channels)           # ['position', 'velocity', 'reward']\nprint(r[50])                # Data at step 50\nprint(r[40:60])             # Slice of data\nprint(r.channel(\"reward\"))  # All reward values\nr.close()\n</code></pre>"},{"location":"getting-started/quickstart/#run-diagnosis","title":"Run Diagnosis","text":"<pre><code>from roboreplay.diagnose import diagnose\n\nresult = diagnose(\"my_first_recording.rrp\")\nprint(result.summary)\nprint(f\"Failures: {len(result.failures)}\")\nprint(f\"Warnings: {len(result.warnings)}\")\n</code></pre>"},{"location":"getting-started/quickstart/#compare-two-runs","title":"Compare Two Runs","text":"<pre><code>from roboreplay import compare\n\ndiff = compare(\"run_a.rrp\", \"run_b.rrp\")\nprint(diff.summary())\nprint(f\"Divergence at step: {diff.divergence_step}\")\n</code></pre>"},{"location":"getting-started/quickstart/#export","title":"Export","text":"<pre><code>from roboreplay.export import export_csv, export_html\n\nexport_csv(\"my_first_recording.rrp\")    # Creates CSV files\nexport_html(\"my_first_recording.rrp\")   # Creates interactive HTML\n</code></pre>"},{"location":"getting-started/quickstart/#use-the-cli","title":"Use the CLI","text":"<pre><code>roboreplay info my_first_recording.rrp\nroboreplay diagnose my_first_recording.rrp\nroboreplay export my_first_recording.rrp --format csv\nroboreplay export my_first_recording.rrp --format html\n</code></pre>"},{"location":"guide/comparing/","title":"Comparing Recordings","text":"<p>Compare two recordings side-by-side to find where they diverge.</p>"},{"location":"guide/comparing/#basic-usage","title":"Basic Usage","text":"<pre><code>from roboreplay import compare\n\ndiff = compare(\"run_success.rrp\", \"run_failure.rrp\")\n\nprint(diff.summary())           # Formatted comparison table\nprint(diff.divergence_step)     # Step where they start differing\nprint(diff.channel_diffs)       # Per-channel statistics\n</code></pre>"},{"location":"guide/comparing/#compareresult","title":"CompareResult","text":"<p>The result contains:</p> <ul> <li><code>name_a</code>/<code>name_b</code> \u2014 Recording names</li> <li><code>steps_a</code>/<code>steps_b</code> \u2014 Step counts</li> <li><code>shared_channels</code> \u2014 Channels present in both recordings</li> <li><code>channel_diffs</code> \u2014 Per-channel diff stats (mean, std, max abs diff)</li> <li><code>divergence_step</code> \u2014 First step where recordings diverge significantly</li> </ul>"},{"location":"guide/comparing/#per-channel-diffs","title":"Per-Channel Diffs","text":"<pre><code>for name, diff in result.channel_diffs.items():\n    print(f\"{name}: mean_a={diff.mean_a:.4f}, mean_b={diff.mean_b:.4f}\")\n    print(f\"  Change: {diff.mean_change_pct:.1f}%\")\n    print(f\"  Max abs diff: {diff.max_abs_diff:.4f}\")\n    print(f\"  Divergence: step {diff.divergence_step}\")\n</code></pre>"},{"location":"guide/comparing/#cli","title":"CLI","text":"<pre><code>roboreplay compare run_success.rrp run_failure.rrp\n</code></pre>"},{"location":"guide/diagnosis/","title":"Diagnosis","text":"<p>RoboReplay provides both statistical and LLM-powered failure analysis.</p>"},{"location":"guide/diagnosis/#statistical-diagnosis","title":"Statistical Diagnosis","text":"<pre><code>from roboreplay.diagnose import diagnose\n\nresult = diagnose(\"recording.rrp\")\n\nprint(result.summary)           # Human-readable summary\nprint(result.failures)          # High-severity anomalies (severity &gt; 0.5)\nprint(result.warnings)          # Medium-severity anomalies (0.2 - 0.5)\nprint(result.has_failures)      # Quick check\n</code></pre>"},{"location":"guide/diagnosis/#anomaly-types","title":"Anomaly Types","text":""},{"location":"guide/diagnosis/#sudden-drops","title":"Sudden Drops","text":"<p>Detects when a signal drops significantly from its recent average.</p>"},{"location":"guide/diagnosis/#spikes","title":"Spikes","text":"<p>Detects outlier values that exceed several standard deviations from the rolling mean.</p>"},{"location":"guide/diagnosis/#flatlines","title":"Flatlines","text":"<p>Detects periods where a previously-varying signal goes completely flat.</p>"},{"location":"guide/diagnosis/#tuning-thresholds","title":"Tuning Thresholds","text":"<pre><code>result = diagnose(\n    \"recording.rrp\",\n    drop_threshold=0.5,      # Sensitivity for drops (0-1)\n    spike_threshold=3.0,     # Std devs for spikes\n    flatline_duration=20,    # Min steps for flatlines\n)\n</code></pre>"},{"location":"guide/diagnosis/#llm-powered-diagnosis","title":"LLM-Powered Diagnosis","text":"<p>For deeper analysis, enable LLM diagnosis (requires <code>pip install roboreplay[diagnose]</code>):</p> <pre><code>result = diagnose(\"recording.rrp\", use_llm=True)\n\nif result.llm_result:\n    print(result.llm_result.explanation)\n    print(result.llm_result.root_causes)\n    print(result.llm_result.recommendations)\n</code></pre> <p>Set your API key via environment variable or parameter:</p> <pre><code>export ANTHROPIC_API_KEY=sk-ant-...\n</code></pre> <pre><code>result = diagnose(\"recording.rrp\", use_llm=True, api_key=\"sk-ant-...\")\n</code></pre>"},{"location":"guide/diagnosis/#cli","title":"CLI","text":"<pre><code>roboreplay diagnose recording.rrp\nroboreplay diagnose recording.rrp --llm\nroboreplay diagnose recording.rrp --llm --api-key sk-ant-...\nroboreplay diagnose recording.rrp --drop-threshold 0.3 --spike-threshold 5.0\n</code></pre>"},{"location":"guide/exporting/","title":"Exporting","text":"<p>RoboReplay supports exporting recordings to CSV and interactive HTML formats.</p>"},{"location":"guide/exporting/#csv-export","title":"CSV Export","text":"<pre><code>from roboreplay.export import export_csv\n\n# Export all channels\nfiles = export_csv(\"recording.rrp\")\n\n# Export specific channels to a directory\nfiles = export_csv(\n    \"recording.rrp\",\n    output_dir=\"exports/\",\n    channels=[\"position\", \"force\"],\n    include_metadata=True,\n    include_events=True,\n)\n\nfor f in files:\n    print(f\"Created: {f}\")\n</code></pre>"},{"location":"guide/exporting/#csv-output-files","title":"CSV Output Files","text":"<ul> <li><code>{name}_channels.csv</code> \u2014 All channel data, one row per step. Multi-dimensional channels are flattened (e.g., <code>position_0</code>, <code>position_1</code>, <code>position_2</code>).</li> <li><code>{name}_events.csv</code> \u2014 Event log with step, type, wall_time, and data.</li> <li><code>{name}_metadata.csv</code> \u2014 Key-value pairs of recording metadata.</li> </ul>"},{"location":"guide/exporting/#html-export","title":"HTML Export","text":"<p>Generates a self-contained HTML file with interactive Chart.js charts:</p> <pre><code>from roboreplay.export import export_html\n\npath = export_html(\"recording.rrp\")\npath = export_html(\"recording.rrp\", output=\"my_report.html\", max_points=5000)\n</code></pre> <p>The HTML file includes:</p> <ul> <li>Interactive time-series charts for each channel</li> <li>Metadata summary header</li> <li>Statistics table</li> <li>Event timeline table</li> <li>LTTB downsampling for large recordings</li> </ul>"},{"location":"guide/exporting/#cli","title":"CLI","text":"<pre><code># CSV export\nroboreplay export recording.rrp --format csv\nroboreplay export recording.rrp --format csv -o exports/\n\n# HTML export\nroboreplay export recording.rrp --format html\nroboreplay export recording.rrp --format html -o report.html\n</code></pre>"},{"location":"guide/gymnasium/","title":"Gymnasium Integration","text":"<p>RoboReplay integrates with Gymnasium via <code>roboreplay.wrap()</code> for automatic recording.</p>"},{"location":"guide/gymnasium/#setup","title":"Setup","text":"<pre><code>pip install roboreplay[gym]\n</code></pre>"},{"location":"guide/gymnasium/#basic-usage","title":"Basic Usage","text":"<pre><code>import gymnasium as gym\nimport roboreplay\n\nenv = gym.make(\"CartPole-v1\")\nwrapped = roboreplay.wrap(env, name=\"cartpole_run\")\n\nobs, info = wrapped.reset()\nfor _ in range(1000):\n    action = wrapped.action_space.sample()\n    obs, reward, terminated, truncated, info = wrapped.step(action)\n    if terminated or truncated:\n        obs, info = wrapped.reset()\n\nwrapped.close()  # Saves recording to cartpole_run.rrp\n</code></pre>"},{"location":"guide/gymnasium/#what-gets-recorded","title":"What Gets Recorded","text":"<p>The wrapper automatically records:</p> <ul> <li><code>observation</code> \u2014 Environment observation at each step</li> <li><code>action</code> \u2014 Action taken at each step</li> <li><code>reward</code> \u2014 Reward received at each step</li> </ul> <p>Events are automatically marked for:</p> <ul> <li><code>episode_reset</code> \u2014 Each call to <code>reset()</code></li> <li><code>episode_terminated</code> \u2014 When <code>terminated=True</code></li> <li><code>episode_truncated</code> \u2014 When <code>truncated=True</code></li> <li><code>recording_end</code> \u2014 On <code>close()</code>, with total steps/episodes count</li> </ul>"},{"location":"guide/gymnasium/#custom-metadata","title":"Custom Metadata","text":"<pre><code>wrapped = roboreplay.wrap(\n    env,\n    name=\"experiment_42\",\n    path=\"data/experiment_42.rrp\",\n    metadata={\n        \"robot\": \"cartpole\",\n        \"task\": \"balance\",\n        \"policy\": \"random\",\n    },\n)\n</code></pre>"},{"location":"guide/gymnasium/#environment-passthrough","title":"Environment Passthrough","text":"<p>The wrapper delegates all attribute access to the underlying environment:</p> <pre><code>wrapped.action_space    # Works \u2014 delegated to env\nwrapped.observation_space  # Works \u2014 delegated to env\nwrapped.spec            # Works \u2014 delegated to env\n</code></pre>"},{"location":"guide/gymnasium/#after-recording","title":"After Recording","text":"<pre><code>from roboreplay import Replay\nfrom roboreplay.diagnose import diagnose\n\nr = Replay(\"cartpole_run.rrp\")\nprint(r)\n\nresult = diagnose(\"cartpole_run.rrp\")\nprint(result.summary)\n</code></pre>"},{"location":"guide/recording/","title":"Recording","text":"<p>The <code>Recorder</code> class is the main interface for capturing robot execution data.</p>"},{"location":"guide/recording/#basic-usage","title":"Basic Usage","text":"<pre><code>from roboreplay import Recorder\nimport numpy as np\n\nrec = Recorder(\"experiment_001\", metadata={\"robot\": \"panda\", \"task\": \"pick_place\"})\nrec.start()\n\nfor step in range(1000):\n    state = get_state()       # Your robot's state\n    action = get_action()     # Your policy output\n    reward = get_reward()\n\n    rec.step(state=state, action=action, reward=reward)\n\nrec.save()\n</code></pre>"},{"location":"guide/recording/#context-manager","title":"Context Manager","text":"<p>The recommended pattern uses a context manager for automatic save:</p> <pre><code>with Recorder(\"experiment_001\") as rec:\n    for step in range(1000):\n        rec.step(state=state, action=action, reward=reward)\n# Automatically saved on exit\n</code></pre>"},{"location":"guide/recording/#schema-inference","title":"Schema Inference","text":"<p>RoboReplay infers the schema from your first <code>step()</code> call. Subsequent calls must provide the same channel names with matching shapes:</p> <pre><code>with Recorder(\"demo\") as rec:\n    # First call defines the schema\n    rec.step(pos=np.array([1.0, 2.0, 3.0]), vel=np.array([0.1]))\n\n    # Must match: pos is (3,), vel is (1,)\n    rec.step(pos=np.array([1.1, 2.1, 3.1]), vel=np.array([0.2]))\n</code></pre>"},{"location":"guide/recording/#events","title":"Events","text":"<p>Mark notable moments during recording:</p> <pre><code>rec.mark_event(\"grasp_start\", {\"force\": 5.0})\nrec.mark_event(\"failure\", {\"type\": \"slip\", \"force_at_fail\": 1.2})\nrec.mark_event(\"episode_end\", {\"success\": True})\n</code></pre>"},{"location":"guide/recording/#data-types","title":"Data Types","text":"<p>Values are automatically converted to <code>float32</code> numpy arrays:</p> <pre><code>rec.step(\n    position=np.array([1.0, 2.0, 3.0]),  # numpy array\n    reward=0.5,                            # Python float \u2192 array([0.5])\n    flag=1,                                # Python int \u2192 array([1.0])\n)\n</code></pre>"},{"location":"guide/recording/#metadata","title":"Metadata","text":"<p>Pass metadata as a dict. <code>robot</code> and <code>task</code> are special fields:</p> <pre><code>rec = Recorder(\"exp\", metadata={\n    \"robot\": \"panda\",          # Stored as top-level field\n    \"task\": \"pick_place\",      # Stored as top-level field\n    \"scene\": \"tabletop\",       # Stored in user_metadata\n    \"policy_version\": \"v2.1\",  # Stored in user_metadata\n})\n</code></pre>"},{"location":"guide/replaying/","title":"Replaying","text":"<p>The <code>Replay</code> class provides random-access reading and navigation of recordings.</p>"},{"location":"guide/replaying/#opening-a-recording","title":"Opening a Recording","text":"<pre><code>from roboreplay import Replay\n\nr = Replay(\"experiment.rrp\")\nprint(r)  # Human-readable summary\n</code></pre>"},{"location":"guide/replaying/#properties","title":"Properties","text":"<pre><code>r.name          # Recording name\nr.robot         # Robot name\nr.task          # Task name\nr.num_steps     # Total steps\nr.channels      # List of channel names\nr.events        # Event log\nr.stats         # Per-channel statistics\nr.metadata      # Full metadata\n</code></pre>"},{"location":"guide/replaying/#indexing-and-slicing","title":"Indexing and Slicing","text":"<pre><code># Single step \u2192 dict of arrays\nframe = r[50]\nprint(frame[\"position\"])  # array at step 50\n\n# Negative indexing\nlast = r[-1]\n\n# Slicing \u2192 dict of arrays\nchunk = r[40:60]\nprint(chunk[\"position\"].shape)  # (20, 3)\n</code></pre>"},{"location":"guide/replaying/#channel-access","title":"Channel Access","text":"<pre><code># Full channel\nall_pos = r.channel(\"position\")  # shape: (num_steps, 3)\n\n# Partial range\nsubset = r.channel(\"position\", start=100, end=200)\n</code></pre>"},{"location":"guide/replaying/#events","title":"Events","text":"<pre><code>for event in r.events.events:\n    print(f\"Step {event.step}: {event.event_type} {event.data}\")\n\n# Filter by type\nfailures = r.events.where(\"failure\")\n</code></pre>"},{"location":"guide/replaying/#plotting","title":"Plotting","text":"<p>Requires <code>matplotlib</code>: <code>pip install roboreplay[viz]</code></p> <pre><code>fig = r.plot(\"gripper_force\")        # Returns matplotlib Figure\nfig = r.plot(\"position\", start=100, end=200)  # Partial range\n</code></pre>"},{"location":"guide/replaying/#context-manager","title":"Context Manager","text":"<pre><code>with Replay(\"experiment.rrp\") as r:\n    print(r.num_steps)\n# Automatically closed\n</code></pre>"}]}